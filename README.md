https://github.com/adrientremblay/comp472-mp1

# comp472-mp1

### To start off
Make sure the goemotions.json is located in the same folder location as all the .ipynb files in this project.

### How to use Q1.ipynb
Step 1) Import the necessary libraries by running the first two code cells.\
Step 2) To get the number of entries for each label, run Cell 3. Cell 4 will print the content of the 
        dictionaries for both the emotions labels and the sentiments labels, with the number of entries assigned to each\
Step 3) This is to create the figures for the label distribution:\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.1) To get the histogram for the sentiments distributions, run the Cell 5. This will also save the figure as png in the same folder as Q1.inpynb.\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.2) To get the pie chart for the emotions distributions, run the Cell 6. This will also save the figure as png in the same folder as Q1.inpynb.

### How to use Q3.ipynb
There are three pretrained word embedding models: word2vec, Wikipedia 2014 and the Fast Wikipedia 
#### Preliminary Steps
Step 1) Import the necessary libraries by running the first code cells under the section "Importing the libraries".\
Step 2) Tokenize each of the posts. Run the cell to do so.\
You can use the cell to check if the amount of tokenized posts is the same as the original one
#### Using the word2vec embedder.
Step 1) Go to the section "Word2Vec". Use the cell to load the word embedding model.\
Step 2) To generate the embeddings for each posts in the \
Step 3) Prepare \
#### Using the Glove Wikipedia model 2014 word 
Step 1) \

#### Using the Fast Wikipedia model
Step 1)\
